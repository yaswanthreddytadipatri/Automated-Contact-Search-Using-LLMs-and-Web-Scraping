{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Contact Search Using LLMs and Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_website(url):\n",
    "#     # Send a GET request to the website\n",
    "#     response = requests.get(url)\n",
    "#     # Check if the request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the HTML content\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#         return soup\n",
    "#     else:\n",
    "#         print(f\"Failed to retrieve the website. Status code: {response.status_code}\")\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# url = 'https://vit.ac.in/contactus'\n",
    "# # url = input(\"Enter the URL: \")\n",
    "# soup = scrape_website(url)\n",
    "# website_text = ''\n",
    "# if soup:\n",
    "#     # Extract text from the website\n",
    "#     website_text = soup.get_text()\n",
    "#     print(website_text)\n",
    "#     # print(soup)\n",
    "#     print(\"####################\\nStep 1 Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Contact Page: https://www.apple.com/in/shop/goto/help\n",
      "Scraping Contact Page: https://www.apple.com/in/contact/\n",
      "Scraping Contact Page: https://www.apple.com/in/shop/goto/help/sales_refunds\n"
     ]
    }
   ],
   "source": [
    "web_data = []\n",
    "\n",
    "def find_contact_pages(base_url):\n",
    "    # Send a GET request to the base URL\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # List of possible contact page keywords\n",
    "    contact_keywords = [\n",
    "        'contact', 'get in touch', 'support', 'help', 'customer service', 'reach us',\n",
    "        'contact us', 'support us', 'connect', 'talk to us', 'inquire', 'service',\n",
    "        'customer care', 'contact center', 'customer support', 'feedback', 'contact form',\n",
    "        'get support', 'contact information', 'contact page', 'service center'\n",
    "    ]\n",
    "\n",
    "    contact_page_urls = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        link_href = link['href']\n",
    "        # Convert relative URL to absolute URL\n",
    "        full_url = urljoin(base_url, link_href)\n",
    "        \n",
    "        # Check if the URL contains any contact keyword and is a proper contact page URL\n",
    "        if any(keyword in full_url.lower() for keyword in contact_keywords):\n",
    "            if base_url in full_url:\n",
    "                contact_page_urls.append(full_url)\n",
    "\n",
    "    return contact_page_urls\n",
    "\n",
    "def scrape_contact_page(url):\n",
    "    # Send a GET request to the contact page URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the contact page. Status code: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract and print all text content\n",
    "    # print(\"Contact Page Content:\")\n",
    "    # print(soup.get_text(separator='\\n', strip=True))\n",
    "    web_data.append(soup.get_text(separator='\\n', strip=True))\n",
    "    # print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Main URL (replace with the website you want to scrape)\n",
    "# main_url = 'https://vit.ac.in/'\n",
    "main_url = input(\"Enter the URL: \")\n",
    "# Find and scrape contact pages\n",
    "contact_urls = find_contact_pages(main_url)\n",
    "if contact_urls:\n",
    "    for contact_url in contact_urls:\n",
    "        print(f\"Scraping Contact Page: {contact_url}\")\n",
    "        scrape_contact_page(contact_url)\n",
    "else:\n",
    "    print(\"No contact pages found.\")\n",
    "\n",
    "# print(web_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM model - llama3:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, it seems that Apple has multiple contact options for various issues. For a physical damage issue with your iPhone, I recommend contacting:\n",
      "\n",
      "**Apple Support**\n",
      "\n",
      "* **Name:** Apple Support\n",
      "* **Designation:** Support Team\n",
      "* **Contact Number:** 000800 0040 01966 (India toll-free number)\n",
      "* **Email:** [Not specified]\n",
      "\n",
      "Alternatively, you can also try reaching out to an **Apple Store** near you for assistance. You can find the nearest store by searching online or using the Apple Store Locator on Apple's website.\n",
      "\n",
      "Please note that these contact details are specific to India and may vary depending on your location.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama3:8b\"\n",
    "\n",
    "problem = input(\"Enter the problem: \")\n",
    "\n",
    "# prompt = f\"Give me the contact deatils based on the problem: {problem} by using the data: {website_text}. Make sure you give me only the Name, Designation, Contact number and email. IF any address then include\"\n",
    "# prompt = f\"Based on the problem described as '{problem}', extract the contact details of the person who should be contacted for resolution from the following text:\\n\\n{website_text}. Note: Make sure you give me only the Name, Designation, Contact number and email. IF any address then include\"\n",
    "prompt = f\"From the following data '{web_data} give me the best contact details that i can contact for the following problme '{problem}. Note: Make sure you give me only the Name, Designation, Contact number and email. IF any address then include.'\"\n",
    "response = ollama.generate(model= model_name,prompt=prompt)\n",
    "\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
